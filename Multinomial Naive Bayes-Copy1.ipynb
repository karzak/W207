{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code was writting from the worked sample seen at the following:\n",
    "\n",
    "https://class.coursera.org/nlp/lecture/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "X = np.array([['Chinese', 'Beijing', 'Chinese'],\n",
    "     ['Chinese', 'Chinese', 'Shanghai'],\n",
    "     ['Chinese', 'Macao'],\n",
    "     ['Tokyo', 'Japan', 'Chinese']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classes\n",
    "y = np.array([0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MNB(object):\n",
    "    \n",
    "    def __init__(self, alpha=1):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # a model has classes\n",
    "        # for each class there are priors\n",
    "        # there are conditional probs for words that don't exists \n",
    "        # in the training set for that model.\n",
    "        # for each class there are words\n",
    "        # for each word there are conditional probabilites\n",
    "        self.model = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        classes = np.unique(y)\n",
    "\n",
    "        total_docs = float(len(y))\n",
    "\n",
    "        # calculate the priors\n",
    "        priors = [i/total_docs for\n",
    "                  i in Counter(y).itervalues()] \n",
    "        \n",
    "        # for the conditional prob denomiators\n",
    "        # of each class\n",
    "        tuw = set()\n",
    "        cp_denom = np.zeros(2)\n",
    "    \n",
    "        for i,c in enumerate(classes):\n",
    "            # for each class we need to store the\n",
    "            # above mentioned data\n",
    "            self.model[c] = {'priors': priors[i],\n",
    "                             'non_exists': 0,\n",
    "                             'words': {}}\n",
    "    \n",
    "            # temporary word storage\n",
    "            temp = {}\n",
    "            \n",
    "            # get all the documents \n",
    "            # for the specific class\n",
    "            pos = c == y\n",
    "            \n",
    "            # count words\n",
    "            for j in X[pos]:\n",
    "                for k in j:\n",
    "                    try:\n",
    "                        temp[k] += 1\n",
    "                    except KeyError:\n",
    "                        temp[k] = 1\n",
    "    \n",
    "            self.model[c]['words'] = temp\n",
    "            \n",
    "            # total unique_words\n",
    "            tuw.update(set(temp.keys()))\n",
    "\n",
    "            # figure out the denominator of the \n",
    "            # conditional probabilities\n",
    "            # vocab + words in class\n",
    "            \n",
    "            cp_denom[i] = np.sum(temp.values())\n",
    "    \n",
    "        # add the vocab count to the denominator\n",
    "        # vocab + word count in class\n",
    "        cp_denom += len(tuw)\n",
    "\n",
    "        # calculate conditional probabilites\n",
    "        # P(word | classz)\n",
    "        for i, kv in enumerate(mnb.model.iteritems()):\n",
    "            k, v = kv\n",
    "            # (word count + smoothing) / (words in class + total unique)\n",
    "            v['words'] = {x:(y+self.alpha)/float(cp_denom[i])\n",
    "                          for x,y in v['words'].iteritems()}\n",
    "\n",
    "    \n",
    "            # there is also the case where the word doesn't \n",
    "            # appear in the training data for the class\n",
    "            # that is our non_exists.\n",
    "            # (0 + smoothing) / (words in class + total unique)\n",
    "            v['non_exists'] = self.alpha/float(cp_denom[i])\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.argmax(self.predict_proba(x), axis=1)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        # for each document,\n",
    "        # check P(class | document)\n",
    "        # by calculating prob for each class\n",
    "        # giving us num_docs by num_class output\n",
    "        # array.\n",
    "\n",
    "        num_classes = len(self.model)\n",
    "        y = np.zeros((len(x), num_classes))\n",
    "        \n",
    "        for i, doc in enumerate(x):\n",
    "            for c in xrange(num_classes):\n",
    "                p = self.model[c]['priors']\n",
    "                for word in doc:\n",
    "                    try:\n",
    "                        p *= self.model[c]['words'][word]\n",
    "                    except KeyError:\n",
    "                        p *= self.model[c]['non_exists']\n",
    "                    \n",
    "                y[i, c] = p\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnb = MNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'non_exists': 0.07142857142857142,\n",
       "  'priors': 0.75,\n",
       "  'words': {'Beijing': 0.14285714285714285,\n",
       "   'Chinese': 0.42857142857142855,\n",
       "   'Macao': 0.14285714285714285,\n",
       "   'Shanghai': 0.14285714285714285}},\n",
       " 1: {'non_exists': 0.1111111111111111,\n",
       "  'priors': 0.25,\n",
       "  'words': {'Chinese': 0.2222222222222222,\n",
       "   'Japan': 0.2222222222222222,\n",
       "   'Tokyo': 0.2222222222222222}}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0196793 ,  0.00137174],\n",
       "       [ 0.0196793 ,  0.00137174],\n",
       "       [ 0.04591837,  0.00617284],\n",
       "       [ 0.00163994,  0.00274348]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = np.array([['Chinese', 'Chinese', 'Chinese', 'Tokyo', 'Japan']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00030121,  0.00013548]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict_proba(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
